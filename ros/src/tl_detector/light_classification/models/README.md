# Traffic-Light Classification by tensorflow models

The steps provided here are taken from [here](https://github.com/alex-lechner/Traffic-Light-Classification).

I add the steps on my environments as below.

## Environments
* OS: Unbuntu 16.04TS
* Python: 2.7
* Tensorflow: 1.4

### Install dependencies
- `pip install tensorflow-gpu==1.4` 
- `sudo apt-get install protobuf-compiler python-pil python-lxml python-tk`
- `git clone https://github.com/tensorflow/models.git`
- Navigate to the `models` and execute `git checkout f7e99c0`.
- Navigate to the `research` folder and execute `protoc object_detection/protos/*.proto --python_out=.`
- Execute ``export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim`` 
- For validating, Execute `python object_detection/builders/model_builder_test.py`

## Training

### Create the workspace structure
Create a folder that will serve as our workspace.

mkdir workspace
cd workspace
mkdir models
mkdir data
mdkir frozen_models


Now we'll get the [dataset](https://github.com/coldKnight/TrafficLight_Detection-TensorFlowAPI#get-the-dataset) for training.
`cd` to the data folder, download and unzip the contents. Move the contents of the data folder generated by unzipping to the current level (instead of them being in /workspace/data/data, they'll be directly in /workspace/data). Remove the empty data folder (workspace/data/data).

Download the labels [file](https://github.com/alex-lechner/Traffic-Light-Classification/blob/master/data/udacity_label_map.pbtxt) in the current directory.

### Get the model

[SSD Inception V2 Coco (11/06/2017)](http://download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_11_06_2017.tar.gz) Pro: Very fast, Con: Low precision

[Faster RCNN Inception V2 Coco (28/01/2018)](http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz) Pro: Good precision, Con: Slow


`cd` to the models directory and untar the model. `cd` inside the model directory and download the appropriate config [file](https://github.com/alex-lechner/Traffic-Light-Classification/tree/master/config).
We'll rename the config file for ease of use. `mv <name>.config pipeline.config`.
Now we need to change the path references of the config file.

Change the `fine_tune_checkpoint` variable to `fine_tune_checkpoint: "models/faster_rcnn_inception_v2_coco_2018_01_28/model.ckpt"`

The actual file to use for training and validation can be changed, in this example we'll configure it so that it uses real image data to train and simulator data to validate.
Change the `train_input_reader` variable to
```
train_input_reader: {
  tf_record_input_reader {
    input_path: "data/real_data.record"
  }
  label_map_path: "data/label_map.pbtxt"
}
```

Changing `eval_input_reader` is not necessary unless you want to validate later, but we'll change it anyway
```
eval_input_reader: {
  tf_record_input_reader {
    input_path: "data/sim_data.record"
  }
  label_map_path: "data/label_map.pbtxt"
  shuffle: true
  num_readers: 1
}
```

`cd` to the base directory (/workspace). Copy the files `train.py` and `export_inference_graph.py` from the `tensorflow/projects/python/models/research/object_detection` to our current directory.

Before training take into account that the process takes well above 1 hour in the best case. **Depending on your GPU and the specific model to train, it can take something between 1-5 hours**.
Execute `python train.py --logtostderr --train_dir=./models/<model_folder>/train/ --pipeline_config_path=./models/<model_folder>/pipeline.config`. Training should start and you'll be able to see the progress.

### Freeze the graph

Open the `export_inference_graph.py` and comment lines 96-98, they should look like this after commenting:
```
#tf.app.flags.mark_flag_as_required('pipeline_config_path')
#tf.app.flags.mark_flag_as_required('trained_checkpoint_prefix')
#tf.app.flags.mark_flag_as_required('output_directory')
```

This is due to the flags attribute not existing in tf 1.3 (they were introduced in 1.4), but don't worry they don't break anything.
Now we can finally run `python export_inference_graph.py --input_type image_tensor --pipeline_config_path ./models/<model_folder>/train/pipeline.config --trained_checkpoint_prefix ./models/<model_folder>/train/model.ckpt-10000 --output_directory ./frozen_models/<model_name>`.

---


Freezing:

You have to make modifications to the tensorflow models repo at `f7e99c0`,
whether you are freezing with 1.3 or 1.4!

For 1.4, see [this branch `ysono/export-with-r1.4`](https://github.com/ysono/tensorflow_models/commits/ysono/export-with-r1.4)

For 1.3, see [this branch `ysono/export-with-r1.3`](https://github.com/ysono/tensorflow_models/commits/ysono/export-with-r1.3)

Though others have had success freezing using tensorflow 1.4, I had to use 1.3 for it to work in Udacity's VM for the project with ROS, tf 1.3, etc installed.


[//]: # (Image References)
[left0000]: ./examples/left0000.jpg
[left0003]: ./examples/left0003.jpg
[left0011]: ./examples/left0011.jpg
[left0027]: ./examples/left0027.jpg
[left0140]: ./examples/left0140.jpg
[left0701]: ./examples/left0701.jpg

[real0000]: ./examples/real0000.png
[real0140]: ./examples/real0140.png
[real0701]: ./examples/real0701.png
[sim0003]: ./examples/sim0003.png
[sim0011]: ./examples/sim0011.png
[sim0027]: ./examples/sim0027.png

# Traffic Light Detection and Classification with TensorFlow Object Detection API
---

#### A brief introduction to the project is available [here](https://medium.com/@Vatsal410/traffic-light-detection-tensorflow-api-c75fdbadac62)

---

AWS AMI with all the software dependencies like TensorFlow and Anaconda (in the community AMIs) - `udacity-carnd-advanced-deep-learning`

### Get the dataset

[Drive location](https://drive.google.com/file/d/0B-Eiyn-CUQtxdUZWMkFfQzdObUE/view?usp=sharing)

### Get the models

Do `git clone https://github.com/tensorflow/models.git` inside the tensorflow directory

Follow the instructions at [this page](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md) for installing some simple dependencies.

**All the files have to be kept inside the `tensorflow/models/research/` directory - data/, config/, data_conversion python files, .record files and utilitites/ ,etc.**


### Location of pre-trained models:
[pre-trained models zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md)

Download the required model tar.gz files and untar them into `/tensorflow/models/research/` directory with `tar -xvzf name_of_tar_file`.

### Creating TFRecord files:

`python data_conversion_udacity_sim.py --output_path sim_data.record`

`python data_conversion_udacity_real.py --output_path real_data.record`

---

## Commands for training the models and saving the weights for inference.

## Using Faster-RCNN model

### For Simulator Data

#### Training

`python object_detection/train.py --pipeline_config_path=config/faster_rcnn-traffic-udacity_sim.config --train_dir=data/sim_training_data/sim_data_capture`

#### Saving for Inference

`python object_detection/export_inference_graph.py --pipeline_config_path=config/faster_rcnn-traffic-udacity_sim.config --trained_checkpoint_prefix=data/sim_training_data/sim_data_capture/model.ckpt-5000 --output_directory=frozen_sim/`


### For Real Data

#### Training

`python object_detection/train.py --pipeline_config_path=config/faster_rcnn-traffic_udacity_real.config --train_dir=data/real_training_data`

#### Saving for Inference

`python object_detection/export_inference_graph.py --pipeline_config_path=config/faster_rcnn-traffic_udacity_real.config --trained_checkpoint_prefix=data/real_training_data/model.ckpt-10000 --output_directory=frozen_real/`

---

## Using Inception SSD v2

### For Simulator Data

#### Training

`python object_detection/train.py --pipeline_config_path=config/ssd_inception-traffic-udacity_sim.config --train_dir=data/sim_training_data/sim_data_capture`

#### Saving for Inference

`python object_detection/export_inference_graph.py --pipeline_config_path=config/ssd_inception-traffic-udacity_sim.config --trained_checkpoint_prefix=data/sim_training_data/sim_data_capture/model.ckpt-5000 --output_directory=frozen_models/frozen_sim_inception/`


### For Real Data

#### Training

`python object_detection/train.py --pipeline_config_path=config/ssd_inception-traffic_udacity_real.config --train_dir=data/real_training_data`

#### Saving for Inference

`python object_detection/export_inference_graph.py --pipeline_config_path=config/ssd_inception-traffic_udacity_real.config --trained_checkpoint_prefix=data/real_training_data/model.ckpt-10000 --output_directory=frozen_models/frozen_real_inception/`

---

## Using MobileNet SSD v1
(Due to some unknown reasons the model gets trained but does not save for inference. Ignoring this for now.)

### For Simulator Data

#### Training

`python object_detection/train.py --pipeline_config_path=config/ssd_mobilenet-traffic-udacity_sim.config --train_dir=data/sim_training_data/sim_data_capture`

#### Saving for Inference

`python object_detection/export_inference_graph.py --pipeline_config_path=config/ssd_mobilenet-traffic-udacity_sim.config --trained_checkpoint_prefix=data/sim_training_data/sim_data_capture/model.ckpt-5000 --output_directory=frozen_models/frozen_sim_mobile/`


### For Real Data

#### Training

`python object_detection/train.py --pipeline_config_path=config/ssd_mobilenet-traffic_udacity_real.config --train_dir=data/real_training_data`

#### Saving for Inference

`python object_detection/export_inference_graph.py --pipeline_config_path=config/ssd_mobilenet-traffic_udacity_real.config --trained_checkpoint_prefix=data/real_training_data/model.ckpt-10000 --output_directory=frozen_models/frozen_real_mobile/`

---

**Inference results can be viewed using the TrafficLightDetection-Inference.ipynb or .html files.**

### Camera Image and Model's Detections      
![alt-text][left0000]
![alt-text][real0000]

![alt-text][left0140]
![alt-text][real0140]

![alt-text][left0701]
![alt-text][real0701]

![alt-text][left0003]
![alt-text][sim0003]

![alt-text][left0011]
![alt-text][sim0011]

![alt-text][left0027]
![alt-text][sim0027]

---

#### Some useful links

- [Uploading/Downloading files between AWS and GoogleDrive](http://olivermarshall.net/how-to-upload-a-file-to-google-drive-from-the-command-line/)

- [Using Jupyter notebooks with AWS](https://medium.com/towards-data-science/setting-up-and-using-jupyter-notebooks-on-aws-61a9648db6c5)

